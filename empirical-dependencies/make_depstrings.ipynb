{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages used: NetworkX -- for tree representation as directed acyclic graphs\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "class Compute_measures(object):\n",
    "    def __init__(self, tree):\n",
    "        self.tree=tree                          # tree encodes the nodes and edges content in dictionary format. It uses directed graph (DiGraph) feature of networkX package. For example, nodes are encoded like this - tree.nodes={1:{form:'this',POS:'PRN'},2:{...}}   \n",
    "        self.root=0                             # ROOT is an abstract node in the tree and is encoded as empty and with name=0    \n",
    "        \n",
    "    def dependency_direction(self, edge):       # Computes the direction of an edge (i.e., dependency) according to relative position of dependent and head  \n",
    "        direction=''\n",
    "        if edge[0]>edge[1]:                     # edge is a list data type in the format [head,dependent]\n",
    "            direction='RL'\n",
    "        else:\n",
    "            direction='LR'\n",
    "\n",
    "        return direction                        # return direction as 'LR' (Left-to-Right) or RL ('Right-to-Left')  \n",
    "\n",
    "    def dependency_distance(self, edge):        # Computes the dependency length i.e., no. of nodes between head and its dependent \n",
    "        dd=0\n",
    "        if edge[0]>edge[1]:                      \n",
    "            for nodex in nx.descendants(self.tree, self.root):        \n",
    "                if edge[1]<nodex<edge[0]:                             # all the nodes that lies linearly between dependent and head   \n",
    "                    dd+=1\n",
    "        else:\n",
    "            for nodex in nx.descendants(self.tree, self.root):\n",
    "                if edge[0]<nodex<edge[1]:\n",
    "                    dd+=1\n",
    "        return dd                              # returns the dependency distance of the edge\n",
    "        \n",
    "    def is_projective(self, edge):             # Checks if an edge is projective or not and returns a boolean value.\n",
    "        projective=True\n",
    "        edge_span=[]                 \n",
    "        if edge[0]>edge[1]:                                      \n",
    "            for nodex in nx.descendants(self.tree, self.root):   \n",
    "                if edge[1]<nodex<edge[0]:\n",
    "                    edge_span.append(nodex)                       \n",
    "        else:\n",
    "            for nodex in nx.descendants(self.tree, self.root):\n",
    "                if edge[0]<nodex<edge[1]:\n",
    "                    edge_span.append(nodex)\n",
    "\n",
    "        flag=0\n",
    "        for nodeI in edge_span:\n",
    "            if not self.tree.nodes[nodeI]['head'] in edge_span:         # if the head of any intervening node exists outside the span of the edge\n",
    "                if not self.tree.nodes[nodeI]['head']==edge[0]:\n",
    "                    if not self.tree.nodes[nodeI]['head']==edge[1]:\n",
    "                        if not self.tree.nodes[nodeI]['deprel']=='punct':\n",
    "                            flag += 1\n",
    "        if not flag==0:\n",
    "            projective=False\n",
    "        return projective\n",
    "    \n",
    "    def edge_degree(self, edge):                                 # Computes the number of edges causing non-projectivity              \n",
    "        eD=0\n",
    "        edge_span=[]                 \n",
    "        if edge[0]>edge[1]:                                      \n",
    "            for nodex in nx.descendants(self.tree, self.root):   \n",
    "                if edge[1]<nodex<edge[0]:\n",
    "                    edge_span.append(nodex)                       \n",
    "        else:\n",
    "            for nodex in nx.descendants(self.tree, self.root):\n",
    "                if edge[0]<nodex<edge[1]:\n",
    "                    edge_span.append(nodex)\n",
    "\n",
    "        for nodeI in edge_span:\n",
    "            if not self.tree.nodes[nodeI]['head'] in edge_span:         # if the head of any intervening node exists outside the span of the edge\n",
    "                if not self.tree.nodes[nodeI]['head']==edge[0]:\n",
    "                    if not self.tree.nodes[nodeI]['head']==edge[1]:\n",
    "                        if not self.tree.nodes[nodeI]['deprel']=='punct':\n",
    "                            eD += 1    \n",
    "        return eD                                                        \n",
    " \n",
    "\n",
    "    def compute_all(self):\n",
    "        # Arity=self.arity()\n",
    "        # Projection_degree=self.projection_degree()\n",
    "        # Gap_degree=self.gap_degree()\n",
    "        direction={}\n",
    "        dep_distance={}\n",
    "        projectivity={}\n",
    "        Edge_degree={}\n",
    "        # endpoint_cross={}\n",
    "        for edgex in self.tree.edges:\n",
    "            direction[edgex]=self.dependency_direction(edgex)\n",
    "            dep_distance[edgex]=self.dependency_distance(edgex)\n",
    "            projectivity[edgex]=self.is_projective(edgex)\n",
    "            Edge_degree[edgex]=self.edge_degree(edgex)\n",
    "            # endpoint_cross[edgex]=self.endpoint_crossing(edgex)\n",
    "\n",
    "        return [direction, dep_distance, projectivity, Edge_degree]\n",
    "        # return [Arity, Projection_degree, Gap_degree, direction, dep_distance, projectivity, Edge_degree, endpoint_cross]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NetworkX package and conllu package\n",
    "import os\n",
    "from io import open\n",
    "from conllu import parse\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import random\n",
    "\n",
    "directory = \"./UD\"                   # directory containing the UD scheme tree files in CONLLU format\n",
    "ud_files = []\n",
    "for root, dirs, files in os.walk(directory):     \n",
    "    for file in files:\n",
    "        if file.endswith('train.conllu') or file.endswith('test.conllu'):\n",
    "            fullpath = os.path.join(root, file)\n",
    "            ud_files.append(fullpath)            # creates a list of path of all files (file of each language) from the directory\n",
    "\n",
    "num_sent=0\n",
    "results = open('results_UD.csv','a')\n",
    "results.write(\"#\"+\"\\t\"+\"TREEBANK\"+\"\\t\"+\"ID\"+\"\\t\"+\"S-LENGTH\"+\"\\t\"+\"EDGE\"+\"\\t\"+\"DIR\"+\"\\t\"+\"D-LENGTH\"+\"\\t\"+\"PROJ\"+\"\\t\"+\"#CROSS\"+\"\\n\")\n",
    "results.close()\n",
    "\n",
    "n_f = 0\n",
    "n_files = len(ud_files)\n",
    "\n",
    "for i in ud_files:                                       # reads file of each language one by one\n",
    "    n_f += 1\n",
    "    lang = str(i).replace(\"./UD\", \"\")        \n",
    "    lang=lang.replace(\"-ud-train.conllu\", \"\")            # lang variable stores the language code\n",
    "    lang=lang.replace(\"-ud-test.conllu\", \"\") \n",
    "    data_file = open(str(i),'r',encoding='utf-8').read()\n",
    "    sentences = []\n",
    "    sentences = parse(data_file)                         # parses the CONLLU format    \n",
    "    n_sent = len(sentences)       \n",
    "    \n",
    "\n",
    "    for sentence in sentences[0:]: # 0:\n",
    "        num_sent += 1\n",
    "        print(str(n_f)+\"/\"+str(n_files), str(num_sent)+\"/\"+str(n_sent))\n",
    "        s_id = sentence.metadata['sent_id']\n",
    "\n",
    "        tree = nx.DiGraph()                              # An empty directed graph (i.e., edges are uni-directional)  \n",
    "        for nodeinfo in sentence[0:]:                    # retrieves information of each node from dependency tree in UD format     \n",
    "            entry=list(nodeinfo.items())\n",
    "            if not entry[7][1]=='punct':\n",
    "                tree.add_node(entry[0][1], form=entry[1][1], lemma=entry[2][1], upostag=entry[3][1], xpostag=entry[4][1], feats=entry[5][1], head=entry[6][1], deprel=entry[7][1], deps=entry[8][1], misc=entry[9][1])                #adds node to the directed graph \n",
    "        ROOT=0\n",
    "        tree.add_node(ROOT)                            # adds an abstract root node to the directed graph\n",
    "            \n",
    "        for nodex in tree.nodes:\n",
    "            if not nodex==0:\n",
    "                if tree.has_node(tree.nodes[nodex]['head']):                                         # to handle disjoint trees\n",
    "                    tree.add_edge(tree.nodes[nodex]['head'],nodex,drel=tree.nodes[nodex]['deprel'])       # adds edges as relation between nodes\n",
    "                if tree.nodes[nodex]['head']==0:\n",
    "                    real_root=nodex\n",
    "        \n",
    "        n = max([x for x in tree.nodes if isinstance(x, int)])\n",
    "        m = len(tree.edges)\n",
    "        get = Compute_measures(tree)\n",
    "\n",
    "        for edgey in tree.edges:\n",
    "            if not edgey[0]==0:\n",
    "                direction_real = get.dependency_direction(edgey)    # direction of the edge in terms of relative linear order of head and its dependent\n",
    "                dep_distance_real=get.dependency_distance(edgey)    # gives the distance between nodes connected by an edge \n",
    "                if get.is_projective(edgey):                   # checks if edge is projective or not\n",
    "                    projectivity_real=1\n",
    "                else:\n",
    "                    projectivity_real=0\n",
    "                edge_degree_real=get.edge_degree(edgey)             # gives the no. of edges crossing an edge\n",
    "                results = open('results_UD.csv','a')\n",
    "                results.write(str(num_sent)+\"\\t\"+str(lang)+\"\\t\"+str(s_id)+\"\\t\"+str(n)+\"\\t\"+str(edgey)+\"\\t\"+str(direction_real)+\"\\t\"+str(dep_distance_real+1)+\"\\t\"+str(projectivity_real)+\"\\t\"+str(edge_degree_real)+\"\\n\")\n",
    "                results.close()\n",
    "        # print(\"\\n-----------------\\n\"+str(tree.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    no_sent = 0\n",
    "    sent_cnt = defaultdict(int)\n",
    "    no_edges = 0\n",
    "    prev_id = ''\n",
    "\n",
    "    edge_dic = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Read data and save edge frequencies in dictionaries\n",
    "    with open('./results_UD.csv', newline='') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader)        #Discard the header\n",
    "        for row in reader:\n",
    "            no_edges += 1\n",
    "            curr_id = row[2]\n",
    "            if prev_id != curr_id:      #We have a new sentence\n",
    "                no_sent += 1\n",
    "                prev_id = curr_id\n",
    "                sent_len = int(row[3])\n",
    "                sent_cnt[sent_len] += 1\n",
    "\n",
    "            edge = tuple(map(lambda x: x-1 ,sorted(literal_eval(row[4]))))      #Reduce indices for later\n",
    "            edge_dic[sent_len][edge] += 1\n",
    "\n",
    "    arraydic = {}\n",
    "    for sl in edge_dic.keys():\n",
    "        arraydic[sl] = {}\n",
    "        arraydic[sl]['edges'] = np.fromiter(edge_dic[sl].keys(), dtype=np.dtype('int,int'))\n",
    "        arraydic[sl]['weights'] = np.fromiter(edge_dic[sl].values(), dtype=int)\n",
    "\n",
    "        # Create mask. Note: entry 0 if the sentence-index occurs in the edge-index, and 1 if it does not\n",
    "        arraydic[sl]['mask'] = mask = np.ones((sl, arraydic[sl]['edges'].size), dtype=bool)\n",
    "        for i, ed in enumerate(arraydic[sl]['edges']):\n",
    "            start, end = ed\n",
    "            mask[start][i] = 0\n",
    "            mask[end][i] = 0\n",
    "\n",
    "    max_s = 499\n",
    "    min_tokens = 1_000_000_000\n",
    "    no_tokens = 0\n",
    "    with open('./depstrings_UD.txt', 'x') as res, tqdm(total=min_tokens) as bar:\n",
    "        while no_tokens < min_tokens:\n",
    "            r_slen = random.choices(list(sent_cnt.keys()), weights=list(sent_cnt.values()), k=1)[0]\n",
    "            no_tokens += r_slen\n",
    "            bar.update(r_slen)\n",
    "            synt_sent = np.full((r_slen), -1, dtype=int)       #Output sentence\n",
    "\n",
    "            eds = arraydic[r_slen]['edges']\n",
    "            no_eds = eds.size\n",
    "            wts = arraydic[r_slen]['weights']\n",
    "            mskmat = arraydic[r_slen]['mask']\n",
    "\n",
    "            # Fill indices according to edges\n",
    "            msk = np.ones((no_eds), dtype=bool)\n",
    "            while len(msk_eds := eds[msk]):\n",
    "                redge = random.choices(msk_eds, weights=wts[msk], k=1)[0]\n",
    "                ed_s, ed_e = redge\n",
    "                synt_sent[[ed_s, ed_e]] = random.randint(0, max_s+1)\n",
    "                msk &= mskmat[ed_s] & mskmat[ed_e]\n",
    "\n",
    "            # Fill remaining indices and write to file\n",
    "            for symb in synt_sent:\n",
    "                if symb == -1:\n",
    "                    symb = random.randint(0, max_s+1)\n",
    "                res.write(f\"{symb} \")\n",
    "            res.write(\"\\n\")\n",
    "\n",
    "            # if not index%10_000:\n",
    "            #     print(f\"{no_tokens}/{min_tokens}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
